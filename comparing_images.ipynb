{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00023658293232054598\n",
      "RMSE: 0.015381252625210536\n",
      "SSIM: 0.9857939398187032\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import mean_squared_error, structural_similarity\n",
    "from skimage import io, color\n",
    "\n",
    "def image_similarity(image1_path, image2_path):\n",
    "    image1 = io.imread(image1_path)\n",
    "    image2 = io.imread(image2_path)\n",
    "\n",
    "    # Ensure both images have the same dimensions and color channels\n",
    "    image1 = color.rgb2gray(image1)\n",
    "    image2 = color.rgb2gray(image2)\n",
    "\n",
    "    # Calculate MSE and RMSE\n",
    "    mse = mean_squared_error(image1, image2)\n",
    "    rmse = mse ** 0.5\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim = structural_similarity(image1, image2)\n",
    "\n",
    "    return mse, rmse, ssim\n",
    "\n",
    "# Example usage\n",
    "image1_path = \"photos/from_facebook.jpg\"\n",
    "image2_path = \"photos/from_gmail.jpg\"\n",
    "mse, rmse, ssim = image_similarity(image1_path, image2_path)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"SSIM:\", ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 731ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Similarity Score: 100.00001192092896%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the Siamese Network architecture\n",
    "def create_siamese_network(input_shape):\n",
    "    input_image = layers.Input(shape=input_shape)\n",
    "    base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_tensor=input_image)\n",
    "\n",
    "    # Flatten the output from the base model\n",
    "    flatten_layer = layers.Flatten()(base_model.output)\n",
    "\n",
    "    # Fully connected layers for feature embedding\n",
    "    fc1 = layers.Dense(512, activation='relu')(flatten_layer)\n",
    "    fc2 = layers.Dense(512, activation='relu')(fc1)\n",
    "\n",
    "    # Final embedding output\n",
    "    embedding = layers.Dense(256)(fc2)\n",
    "\n",
    "    # Create the siamese model\n",
    "    siamese_model = Model(inputs=input_image, outputs=embedding)\n",
    "    return siamese_model\n",
    "\n",
    "# Function to calculate similarity between two embeddings\n",
    "def similarity_metric(embedding1, embedding2):\n",
    "    # Flatten the arrays to 1D\n",
    "    embedding1 = np.squeeze(embedding1)\n",
    "    embedding2 = np.squeeze(embedding2)\n",
    "\n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "\n",
    "    # Calculate the norms of the arrays\n",
    "    norm_embedding1 = np.linalg.norm(embedding1)\n",
    "    norm_embedding2 = np.linalg.norm(embedding2)\n",
    "\n",
    "    # Calculate the similarity score\n",
    "    similarity_score = dot_product / (norm_embedding1 * norm_embedding2)\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Load images from paths\n",
    "def load_image(image_path):\n",
    "    image = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Load images from paths\n",
    "image1_path = \"photos/edited.png\"\n",
    "image2_path = \"photos/edited.png\"\n",
    "\n",
    "image1 = load_image(image1_path)\n",
    "image2 = load_image(image2_path)\n",
    "\n",
    "# Create the Siamese Network\n",
    "input_shape = (224, 224, 3)\n",
    "siamese_model = create_siamese_network(input_shape)\n",
    "\n",
    "# # Load pre-trained weights (optional)\n",
    "# siamese_model.load_weights(\"path/to/pretrained_weights.h5\")\n",
    "\n",
    "# Get the embeddings for the two images\n",
    "embedding1 = siamese_model.predict(image1)\n",
    "embedding2 = siamese_model.predict(image2)\n",
    "\n",
    "# Calculate similarity metric\n",
    "similarity_score = similarity_metric(embedding1, embedding2) * 100\n",
    "\n",
    "print(f'Similarity Score: {similarity_score}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photos/edited.png and photos/edited.png are Authentic (Expected: Authentic). Similarity Score: 0.9999999403953552\n",
      "photos/compressed0.jpg and photos/compressed10.jpg are Not Authentic (Expected: Authentic). Similarity Score: 0.8813328742980957\n",
      "photos/compressed0.jpg and photos/compressed90.jpg are Not Authentic (Expected: Authentic). Similarity Score: 0.8889349102973938\n",
      "photos/compressed10.jpg and photos/compressed90.jpg are Authentic (Expected: Authentic). Similarity Score: 0.9510352611541748\n",
      "photos/compressed30.jpg and photos/compressed60.jpg are Authentic (Expected: Authentic). Similarity Score: 0.9830877780914307\n",
      "photos/from_gmail.jpg and photos/from_facebook.jpg are Authentic (Expected: Authentic). Similarity Score: 0.9833754897117615\n",
      "photos/from_gmail.jpg and photos/from_gmail.jpg are Authentic (Expected: Authentic). Similarity Score: 1.0\n",
      "photos/edited.png and photos/onedrive_unedited.jpg are Not Authentic (Expected: Not Authentic). Similarity Score: 0.8018050789833069\n",
      "photos/edited.png and photos/refrigerator.webp are Not Authentic (Expected: Not Authentic). Similarity Score: 0.5054042935371399\n",
      "photos/compressed60.jpg and photos/compressed90.jpg are Authentic (Expected: Authentic). Similarity Score: 0.9902726411819458\n",
      "False Positives: 0\n",
      "False Negatives: 2\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from pathlib import Path  # Import the Path module\n",
    "\n",
    "# Define the Siamese Network architecture\n",
    "def create_siamese_network(input_shape):\n",
    "    input_image = layers.Input(shape=input_shape)\n",
    "    base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_tensor=input_image)\n",
    "\n",
    "    # Flatten the output from the base model\n",
    "    flatten_layer = layers.Flatten()(base_model.output)\n",
    "\n",
    "    # Fully connected layers for feature embedding\n",
    "    fc1 = layers.Dense(512, activation='relu')(flatten_layer)\n",
    "    fc2 = layers.Dense(512, activation='relu')(fc1)\n",
    "\n",
    "    # Final embedding output\n",
    "    embedding = layers.Dense(256)(fc2)\n",
    "\n",
    "    # Create the siamese model\n",
    "    siamese_model = Model(inputs=input_image, outputs=embedding)\n",
    "    return siamese_model\n",
    "\n",
    "# Function to calculate similarity between two embeddings\n",
    "def similarity_metric(embedding1, embedding2):\n",
    "    # Flatten the arrays to 1D\n",
    "    embedding1 = np.squeeze(embedding1)\n",
    "    embedding2 = np.squeeze(embedding2)\n",
    "\n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "\n",
    "    # Calculate the norms of the arrays\n",
    "    norm_embedding1 = np.linalg.norm(embedding1)\n",
    "    norm_embedding2 = np.linalg.norm(embedding2)\n",
    "\n",
    "    # Calculate the similarity score\n",
    "    similarity_score = dot_product / (norm_embedding1 * norm_embedding2)\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Load images from paths\n",
    "def load_image(image_path):\n",
    "    image = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Create the Siamese Network\n",
    "input_shape = (224, 224, 3)\n",
    "siamese_model = create_siamese_network(input_shape)\n",
    "\n",
    "# List of image pairs to compare\n",
    "image_pairs = [\n",
    "    (\"photos/edited.png\", \"photos/edited.png\", True),\n",
    "    (\"photos/compressed0.jpg\", \"photos/compressed10.jpg\", True),  # Authentic pair\n",
    "    (\"photos/compressed0.jpg\", \"photos/compressed90.jpg\", True),\n",
    "    (\"photos/compressed10.jpg\", \"photos/compressed90.jpg\", True),\n",
    "    (\"photos/compressed30.jpg\", \"photos/compressed60.jpg\", True),\n",
    "    (\"photos/from_gmail.jpg\", \"photos/from_facebook.jpg\", True),\n",
    "    (\"photos/from_gmail.jpg\", \"photos/from_gmail.jpg\", True),\n",
    "    (\"photos/edited.png\", \"photos/onedrive_unedited.jpg\", False),\n",
    "    (\"photos/edited.png\", \"photos/refrigerator.webp\", False),  # Non-authentic pair\n",
    "    (\"photos/compressed60.jpg\", \"photos/compressed90.jpg\", True),\n",
    "]\n",
    "\n",
    "# Threshold for authenticity\n",
    "threshold = 0.90\n",
    "\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "for image1_path, image2_path, is_authentic in image_pairs:\n",
    "    # Load images from paths (passing the string directly)\n",
    "    image1 = load_image(image1_path)\n",
    "    image2 = load_image(image2_path)\n",
    "\n",
    "    # Get the embeddings for the two images\n",
    "    embedding1 = siamese_model.predict(image1, verbose=0)\n",
    "    embedding2 = siamese_model.predict(image2, verbose=0)\n",
    "\n",
    "    # Calculate similarity metric\n",
    "    similarity_score = similarity_metric(embedding1, embedding2)\n",
    "\n",
    "    # Determine if the pair is authentic or not\n",
    "    if is_authentic:\n",
    "        authenticity = \"Authentic\" if similarity_score > threshold else \"Not Authentic\"\n",
    "    else:\n",
    "        authenticity = \"Not Authentic\" if similarity_score < threshold else \"Authentic\"\n",
    "\n",
    "    if is_authentic and similarity_score > threshold:\n",
    "        correct_predictions += 1\n",
    "    elif not is_authentic and similarity_score <= threshold:\n",
    "        correct_predictions += 1\n",
    "    elif not is_authentic and similarity_score > threshold:\n",
    "        false_positives += 1\n",
    "    elif is_authentic and similarity_score <= threshold:\n",
    "        false_negatives += 1\n",
    "\n",
    "    print(f\"{image1_path} and {image2_path} are {authenticity} (Expected: {'Authentic' if is_authentic else 'Not Authentic'}). Similarity Score: {similarity_score}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "total_pairs = len(image_pairs)\n",
    "accuracy = correct_predictions / total_pairs * 100\n",
    "\n",
    "# Print counts of false positives and false negatives\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "\n",
    "# Print accuracy and percentage of correct predictions\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internshipvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
